{
    "accessoryFiles": {},
    "language": "WDL_1_0",
    "outputs": {
        "bamMergePreprocessing.outputGroups": {
            "is": "list",
            "keys": {
                "outputIdentifier": "STRING"
            },
            "outputs": {
                "bam": "file",
                "bamIndex": "file"
            }
        },
        "bamMergePreprocessing.recalibrationReport": "optional-file",
        "bamMergePreprocessing.recalibrationTable": "optional-file"
    },
    "parameters": {
        "bamMergePreprocessing.analyzeCovariates.additionalParams": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.analyzeCovariates.cores": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.analyzeCovariates.jobMemory": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.analyzeCovariates.modules": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.analyzeCovariates.outputFileName": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.analyzeCovariates.overhead": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.analyzeCovariates.timeout": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.applyBaseQualityScoreRecalibration.additionalParams": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.applyBaseQualityScoreRecalibration.cores": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.applyBaseQualityScoreRecalibration.jobMemory": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.applyBaseQualityScoreRecalibration.modules": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.applyBaseQualityScoreRecalibration.outputFileName": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.applyBaseQualityScoreRecalibration.overhead": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.applyBaseQualityScoreRecalibration.suffix": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.applyBaseQualityScoreRecalibration.timeout": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.baseQualityScoreRecalibration.additionalParams": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.baseQualityScoreRecalibration.cores": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.baseQualityScoreRecalibration.intervals": {
            "inner": {
                "inner": "string",
                "is": "list"
            },
            "is": "optional"
        },
        "bamMergePreprocessing.baseQualityScoreRecalibration.jobMemory": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.baseQualityScoreRecalibration.knownSites": {
            "inner": "string",
            "is": "list"
        },
        "bamMergePreprocessing.baseQualityScoreRecalibration.modules": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.baseQualityScoreRecalibration.outputFileName": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.baseQualityScoreRecalibration.overhead": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.baseQualityScoreRecalibration.timeout": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.collectFilesBySample.cores": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.collectFilesBySample.jobMemory": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.collectFilesBySample.modules": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.collectFilesBySample.timeout": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.doBqsr": {
            "inner": "boolean",
            "is": "optional"
        },
        "bamMergePreprocessing.doFilter": {
            "inner": "boolean",
            "is": "optional"
        },
        "bamMergePreprocessing.doIndelRealignment": {
            "inner": "boolean",
            "is": "optional"
        },
        "bamMergePreprocessing.doMarkDuplicates": {
            "inner": "boolean",
            "is": "optional"
        },
        "bamMergePreprocessing.doSplitNCigarReads": {
            "inner": "boolean",
            "is": "optional"
        },
        "bamMergePreprocessing.gatherBQSRReports.additionalParams": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.gatherBQSRReports.cores": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.gatherBQSRReports.jobMemory": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.gatherBQSRReports.modules": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.gatherBQSRReports.outputFileName": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.gatherBQSRReports.overhead": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.gatherBQSRReports.timeout": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.indelRealign.additionalParams": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.indelRealign.cores": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.indelRealign.gatkJar": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.indelRealign.jobMemory": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.indelRealign.knownAlleles": {
            "inner": "string",
            "is": "list"
        },
        "bamMergePreprocessing.indelRealign.modules": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.indelRealign.overhead": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.indelRealign.timeout": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.inputGroups": {
            "inner": {
                "fields": {
                    "bamAndBamIndexInputs": {
                        "inner": {
                            "fields": {
                                "bam": "file",
                                "bamIndex": "file"
                            },
                            "is": "object"
                        },
                        "is": "list"
                    },
                    "outputIdentifier": "string"
                },
                "is": "object"
            },
            "is": "list"
        },
        "bamMergePreprocessing.intervalsToParallelizeByString": "string",
        "bamMergePreprocessing.mergeSplitByIntervalBams.additionalParams": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.mergeSplitByIntervalBams.cores": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.mergeSplitByIntervalBams.jobMemory": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.mergeSplitByIntervalBams.modules": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.mergeSplitByIntervalBams.overhead": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.mergeSplitByIntervalBams.timeout": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.preprocessBam.defaultRuntimeAttributes": {
            "inner": {
                "fields": {
                    "cores": "integer",
                    "memory": "integer",
                    "modules": "string",
                    "overhead": "integer",
                    "timeout": "integer"
                },
                "is": "object"
            },
            "is": "optional"
        },
        "bamMergePreprocessing.preprocessBam.filterAdditionalParams": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.preprocessBam.filterFlags": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.preprocessBam.filterSuffix": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.preprocessBam.markDuplicatesAdditionalParams": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.preprocessBam.markDuplicatesSuffix": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.preprocessBam.minMapQuality": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.preprocessBam.opticalDuplicatePixelDistance": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.preprocessBam.readFilters": {
            "inner": {
                "inner": "string",
                "is": "list"
            },
            "is": "optional"
        },
        "bamMergePreprocessing.preprocessBam.refactorCigarString": {
            "inner": "boolean",
            "is": "optional"
        },
        "bamMergePreprocessing.preprocessBam.removeDuplicates": {
            "inner": "boolean",
            "is": "optional"
        },
        "bamMergePreprocessing.preprocessBam.splitNCigarReadsAdditionalParams": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.preprocessBam.splitNCigarReadsSuffix": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.preprocessBam.temporaryWorkingDir": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.preprocessingBamRuntimeAttributes": {
            "inner": {
                "inner": {
                    "fields": {
                        "cores": {
                            "inner": "integer",
                            "is": "optional"
                        },
                        "id": {
                            "inner": "string",
                            "is": "optional"
                        },
                        "memory": {
                            "inner": "integer",
                            "is": "optional"
                        },
                        "modules": {
                            "inner": "string",
                            "is": "optional"
                        },
                        "overhead": {
                            "inner": "integer",
                            "is": "optional"
                        },
                        "timeout": {
                            "inner": "integer",
                            "is": "optional"
                        }
                    },
                    "is": "object"
                },
                "is": "list"
            },
            "is": "optional"
        },
        "bamMergePreprocessing.realignerTargetCreator.additionalParams": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.realignerTargetCreator.cores": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.realignerTargetCreator.downsamplingType": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.realignerTargetCreator.gatkJar": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.realignerTargetCreator.jobMemory": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.realignerTargetCreator.knownIndels": {
            "inner": "string",
            "is": "list"
        },
        "bamMergePreprocessing.realignerTargetCreator.modules": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.realignerTargetCreator.overhead": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.realignerTargetCreator.timeout": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.reference": "string",
        "bamMergePreprocessing.splitStringToArray.cores": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.splitStringToArray.jobMemory": {
            "inner": "integer",
            "is": "optional"
        },
        "bamMergePreprocessing.splitStringToArray.lineSeparator": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.splitStringToArray.modules": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.splitStringToArray.recordSeparator": {
            "inner": "string",
            "is": "optional"
        },
        "bamMergePreprocessing.splitStringToArray.timeout": {
            "inner": "integer",
            "is": "optional"
        }
    },
    "workflow": "version 1.0\n\nworkflow bamMergePreprocessing {\n\n  input {\n    Array[InputGroup] inputGroups\n    String intervalsToParallelizeByString\n    Boolean doFilter = true\n    Boolean doMarkDuplicates = true\n    Boolean doSplitNCigarReads = false\n    Boolean doIndelRealignment = true\n    Boolean doBqsr = true\n    String reference\n\n    # preprocessingBam runtime attributes overrides\n    # map access with missing key (e.g. an interval that does not need an override) is not supported\n    # see: https://github.com/openwdl/wdl/issues/305\n    #Map[String, RuntimeAttributes]? preprocessingBamRuntimeAttributes\n    Array[RuntimeAttributes] preprocessingBamRuntimeAttributes = []\n  }\n\n  parameter_meta {\n    inputGroups: \"Array of objects describing sets of bams to merge together and the merged file name. These merged bams will be cocleaned together and output separately (by merged name).\"\n    intervalsToParallelizeByString: \"Comma separated list of intervals to split by (e.g. chr1,chr2,chr3+chr4).\"\n    doFilter: \"Enable/disable Samtools filtering.\"\n    doMarkDuplicates: \"Enable/disable GATK4 MarkDuplicates.\"\n    doSplitNCigarReads: \"Enable/disable GATK4 SplitNCigarReads.\"\n    doIndelRealignment: \"Enable/disable GATK3 RealignerTargetCreator + IndelRealigner.\"\n    doBqsr: \"Enable/disable GATK4 BQSR.\"\n    reference: \"Path to reference file.\"\n    preprocessingBamRuntimeAttributes: \"Interval specific runtime attributes to use as overrides for the defaults.\"\n  }\n\n  meta {\n    author: \"Michael Laszloffy\"\n    email: \"michael.laszloffy@oicr.on.ca\"\n    description: \"WDL workflow to filter, merge, mark duplicates, indel realign and base quality score recalibrate groups of related (e.g. by library, donor, project) lane level alignments.\"\n    dependencies: [\n      {\n        name: \"samtools/1.9\",\n        url: \"http://www.htslib.org/\"\n      },\n      {\n        name: \"gatk/4.1.6.0\",\n        url: \"https://gatk.broadinstitute.org\"\n      },\n      {\n        name: \"gatk/3.6-0\",\n        url: \"https://gatk.broadinstitute.org\"\n      },\n      {\n       name: \"python/3.7\",\n       url: \"https://www.python.org\"\n      }\n    ]\n    output_meta: {\n      outputGroups: \"Array of objects with outputIdentifier (from inputGroups) and the final merged bam and bamIndex.\",\n      recalibrationReport: \"Recalibration report pdf (if BQSR enabled).\",\n      recalibrationTable: \"Recalibration csv that was used by BQSR (if BQSR enabled).\"\n    }\n  }\n\n  call splitStringToArray {\n    input:\n      str = intervalsToParallelizeByString\n  }\n  Array[Intervals] intervalsToParallelizeBy = splitStringToArray.intervalsList.intervalsList\n\n  scatter (intervals in intervalsToParallelizeBy) {\n    scatter (i in inputGroups) {\n      scatter(bamAndBamIndexInput in i.bamAndBamIndexInputs) {\n        File inputGroupBam = bamAndBamIndexInput.bam\n        File inputGroupBamIndex = bamAndBamIndexInput.bamIndex\n      }\n      Array[File] inputGroupBams = inputGroupBam\n      Array[File] inputGroupBamIndexes = inputGroupBamIndex\n\n      # map access with missing key (e.g. an interval that does not need an override) is not supported\n      # see: https://github.com/openwdl/wdl/issues/305\n      #RuntimeAttribute? runtimeAttributeOverride = preprocessingBamRuntimeAttributes[intervals.id]\n      scatter (p in preprocessingBamRuntimeAttributes) {\n        if(defined(p.id)) {\n          String id = select_first([p.id])\n          if(id == i.outputIdentifier + \".\" + intervals.id) {\n            RuntimeAttributes? inputGroupAndIntervalRuntimeAttributesOverride = p\n          }\n          if(id == intervals.id) {\n            RuntimeAttributes? intervalRuntimeAttributesOverride = p\n          }\n          if(id == \"*\") {\n            RuntimeAttributes? wildcardRuntimeAttributesOverride = p\n          }\n        }\n      }\n      # collect interval and wildcard runtime attribute overrides\n      Array[RuntimeAttributes] runtimeAttributeOverrides = flatten([select_all(inputGroupAndIntervalRuntimeAttributesOverride),\n                                                                    select_all(intervalRuntimeAttributesOverride),\n                                                                    select_all(wildcardRuntimeAttributesOverride)])\n      if(length(runtimeAttributeOverrides) > 0) {\n        # create a RuntimeAttributes optional\n        RuntimeAttributes runtimeAttributesOverride = runtimeAttributeOverrides[0]\n      }\n\n      call preprocessBam {\n        input:\n          bams = inputGroupBams,\n          bamIndexes = inputGroupBamIndexes,\n          intervals = intervals.intervalsList,\n          outputFileName = i.outputIdentifier,\n          reference = reference,\n          doFilter = doFilter,\n          doMarkDuplicates = doMarkDuplicates,\n          doSplitNCigarReads = doSplitNCigarReads,\n          runtimeAttributes = runtimeAttributesOverride\n      }\n    }\n    Array[File] preprocessedBams = preprocessBam.preprocessedBam\n    Array[File] preprocessedBamIndexes = preprocessBam.preprocessedBamIndex\n\n    # indel realignment combines samples (nWayOut) and is parallized by chromosome\n    if(doIndelRealignment) {\n      call realignerTargetCreator {\n        input:\n          bams = preprocessedBams,\n          bamIndexes = preprocessedBamIndexes,\n          intervals = intervals.intervalsList,\n          reference = reference\n      }\n\n      call indelRealign {\n        input:\n          bams = preprocessedBams,\n          bamIndexes = preprocessedBamIndexes,\n          intervals = intervals.intervalsList,\n          targetIntervals = realignerTargetCreator.targetIntervals,\n          reference = reference\n      }\n      Array[File] indelRealignedBams = indelRealign.indelRealignedBams\n      Array[File] indelRealignedBamIndexes = indelRealign.indelRealignedBamIndexes\n    }\n\n    if(doBqsr) {\n      call baseQualityScoreRecalibration {\n        input:\n          bams = select_first([indelRealignedBams, preprocessedBams]),\n          reference = reference\n      }\n    }\n    Array[File] processedBamsByInterval = select_first([indelRealignedBams, preprocessedBams])\n    Array[File] processedBamIndexesByInterval = select_first([indelRealignedBamIndexes, preprocessedBamIndexes])\n    File? recalibrationTableByInterval = baseQualityScoreRecalibration.recalibrationTable\n  }\n  Array[File] processedBams = flatten(processedBamsByInterval)\n  Array[File] processedBamIndexes = flatten(processedBamIndexesByInterval)\n\n  if(doBqsr) {\n    call gatherBQSRReports {\n      input:\n        recalibrationTables = select_all(recalibrationTableByInterval)\n    }\n\n    call analyzeCovariates {\n      input:\n        recalibrationTable = gatherBQSRReports.recalibrationTable\n    }\n\n    scatter(bam in processedBams) {\n      call applyBaseQualityScoreRecalibration {\n        input:\n          recalibrationTable = gatherBQSRReports.recalibrationTable,\n          bam = bam\n      }\n    }\n    Array[File] recalibratedBams = applyBaseQualityScoreRecalibration.recalibratedBam\n    Array[File] recalibratedBamIndexes = applyBaseQualityScoreRecalibration.recalibratedBamIndex\n  }\n\n  call collectFilesBySample {\n    input:\n      inputGroups = inputGroups,\n      bams = select_first([recalibratedBams, processedBams]),\n      bamIndexes = select_first([recalibratedBamIndexes, processedBamIndexes])\n  }\n\n  scatter(o in collectFilesBySample.filesByOutputIdentifier.collectionGroups) {\n    if(length(o.bams) > 1) {\n      call mergeBams as mergeSplitByIntervalBams {\n        input:\n          bams = o.bams,\n          outputFileName = o.outputFileName,\n          suffix = \"\" # collectFilesBySample task generates the file name\n      }\n    }\n    OutputGroup outputGroup = { \"outputIdentifier\": o.outputIdentifier,\n                                \"bam\": select_first([mergeSplitByIntervalBams.mergedBam, o.bams[0]]),\n                                \"bamIndex\": select_first([mergeSplitByIntervalBams.mergedBamIndex, o.bamIndexes[0]])}\n  }\n\n  output {\n    Array[OutputGroup] outputGroups = outputGroup\n    File? recalibrationReport = analyzeCovariates.recalibrationReport\n    File? recalibrationTable = gatherBQSRReports.recalibrationTable\n  }\n}\n\ntask splitStringToArray {\n  input {\n    String str\n    String lineSeparator = \",\"\n    String recordSeparator = \"+\"\n\n    Int jobMemory = 1\n    Int cores = 1\n    Int timeout = 1\n    String modules = \"python/3.7\"\n  }\n\n  command <<<\n    set -euo pipefail\n\n    python3 <<CODE\n    import json\n\n    intervals = []\n    for i in \"~{str}\".split(\"~{lineSeparator}\"):\n      interval = {\"id\": i, \"intervalsList\": i.split(\"~{recordSeparator}\")}\n      intervals.append(interval)\n\n    # wrap intervals in intervalsList for cromwell\n    print(json.dumps({\"intervalsList\": intervals}))\n    CODE\n  >>>\n\n  output {\n    # cromwell doesn't support read_json where the json is an array of objects...\n    #Array[Intervals] intervals = read_json(stdout())\n    IntervalsList intervalsList = read_json(stdout())\n  }\n\n  runtime {\n    memory: \"~{jobMemory} GB\"\n    cpu: \"~{cores}\"\n    timeout: \"~{timeout}\"\n    modules: \"~{modules}\"\n  }\n\n  parameter_meta {\n    str: \"Interval string to split (e.g. chr1,chr2,chr3+chr4).\"\n    lineSeparator: \"Interval group separator - these are the intervals to split by.\"\n    recordSeparator: \"Interval interval group separator - this can be used to combine multiple intervals into one group.\"\n    jobMemory: \"Memory allocated to job (in GB).\"\n    cores: \"The number of cores to allocate to the job.\"\n    timeout: \"Maximum amount of time (in hours) the task can run for.\"\n    modules: \"Environment module name and version to load (space separated) before command execution.\"\n  }\n}\n\ntask preprocessBam {\n  input {\n    Boolean doFilter = true\n    Boolean doMarkDuplicates = true\n    Boolean doSplitNCigarReads = false\n\n    String outputFileName\n\n    # by default write tmp files to the current working directory (cromwell task directory)\n    # $TMPDIR is set by Cromwell\n    # $TMP is set by Univa\n    String temporaryWorkingDir = \"\"\n\n    Array[File] bams\n    Array[File] bamIndexes\n    Array[String] intervals\n\n    # filter parameters\n    String filterSuffix = \".filter\"\n    Int filterFlags = 260\n    Int? minMapQuality\n    String? filterAdditionalParams\n\n    # mark duplicates\n    String markDuplicatesSuffix = \".deduped\"\n    Boolean removeDuplicates = false\n    Int opticalDuplicatePixelDistance = 100\n    String? markDuplicatesAdditionalParams\n\n    # split N cigar reads\n    String splitNCigarReadsSuffix = \".split\"\n    String reference\n    Boolean refactorCigarString = false\n    Array[String] readFilters = []\n    String? splitNCigarReadsAdditionalParams\n\n    RuntimeAttributes? runtimeAttributes\n    DefaultRuntimeAttributes defaultRuntimeAttributes = {\n      \"memory\": 24,\n      \"overhead\": 6,\n      \"cores\": 1,\n      \"timeout\": 6,\n      \"modules\": \"samtools/1.9 gatk/4.1.6.0\"\n    }\n  }\n\n  # select_first doesn't like struct?.field? and winstanley doesn't like empty object \"{}\"\n  RuntimeAttributes optionalRuntimeAttributes = select_first([runtimeAttributes, {\"id\":\"using_defaults\"}])\n\n  # get provided runtime attributes or use defaults\n  Int memory = select_first([optionalRuntimeAttributes.memory, defaultRuntimeAttributes.memory])\n  Int overhead = select_first([optionalRuntimeAttributes.overhead, defaultRuntimeAttributes.overhead])\n  Int cores = select_first([optionalRuntimeAttributes.cores, defaultRuntimeAttributes.cores])\n  Int timeout = select_first([optionalRuntimeAttributes.timeout, defaultRuntimeAttributes.timeout])\n  String modules = select_first([optionalRuntimeAttributes.modules, defaultRuntimeAttributes.modules])\n\n  String workingDir = if temporaryWorkingDir == \"\" then \"\" else \"~{temporaryWorkingDir}/\"\n\n  String baseFileName = \"~{outputFileName}\"\n\n  String filteredFileName = if doFilter then\n                            \"~{baseFileName}.filter\"\n                           else\n                            \"~{baseFileName}\"\n  String filteredFilePath = if doMarkDuplicates || doSplitNCigarReads then\n                            \"~{workingDir}~{filteredFileName}\"\n                           else \"~{filteredFileName}\"\n\n  String markDuplicatesFileName = if doMarkDuplicates then\n                                  \"~{filteredFileName}.deduped\"\n                                 else\n                                  \"~{filteredFileName}\"\n  String markDuplicatesFilePath = if doSplitNCigarReads then\n                                  \"~{workingDir}~{markDuplicatesFileName}\"\n                                 else\n                                  \"~{markDuplicatesFileName}\"\n\n  String splitNCigarReadsFileName = if doSplitNCigarReads then\n                                    \"~{markDuplicatesFileName}.split\"\n                                   else\n                                    \"~{markDuplicatesFileName}\"\n  String splitNCigarReadsFilePath = if false then # there are no downstream steps, so don't write to temp dir\n                                    \"~{workingDir}~{splitNCigarReadsFileName}\"\n                                   else\n                                    \"~{splitNCigarReadsFileName}\"\n\n  # workaround for this issue https://github.com/broadinstitute/cromwell/issues/5092\n  # ~{sep = \" \" prefix(\"--read-filter \", readFilters)}\n  Array[String] prefixedReadFilters = prefix(\"--read-filter \", readFilters)\n\n  command <<<\n    set -euxo pipefail\n    inputBams=\"~{sep=\" \" bams}\"\n    inputBamIndexes=\"~{sep=\" \" bamIndexes}\"\n\n    # filter\n    if [ \"~{doFilter}\" = true ]; then\n      outputBams=()\n      outputBamIndexes=()\n      for inputBam in $inputBams; do\n        filename=\"$(basename $inputBam \".bam\")\"\n        outputBam=\"~{workingDir}${filename}.filtered.bam\"\n        outputBamIndex=\"~{workingDir}${filename}.filtered.bai\"\n        samtools view -b \\\n        -F ~{filterFlags} \\\n        ~{\"-q \" + minMapQuality} \\\n        ~{filterAdditionalParams} \\\n        $inputBam \\\n        ~{sep=\" \" intervals} > $outputBam\n        samtools index $outputBam $outputBamIndex\n        outputBams+=(\"$outputBam\")\n        outputBamIndexes+=(\"$outputBamIndex\")\n      done\n      # set inputs for next step\n      inputBams=(\"${outputBams[@]}\")\n      inputBamIndexes=(\"${outputBamIndexes[@]}\")\n    else\n      outputBams=()\n      outputBamIndexes=()\n      for inputBam in $inputBams; do\n        filename=\"$(basename $inputBam \".bam\")\"\n        outputBam=\"~{workingDir}${filename}.bam\"\n        outputBamIndex=\"~{workingDir}${filename}.bai\"\n        samtools view -b \\\n        $inputBam \\\n        ~{sep=\" \" intervals} > $outputBam\n        samtools index $outputBam $outputBamIndex\n        outputBams+=(\"$outputBam\")\n        outputBamIndexes+=(\"$outputBamIndex\")\n      done\n      # set inputs for next step\n      inputBams=(\"${outputBams[@]}\")\n      inputBamIndexes=(\"${outputBamIndexes[@]}\")\n    fi\n\n    # mark duplicates\n    if [ \"~{doMarkDuplicates}\" = true ]; then\n      outputBams=()\n      outputBamIndexes=()\n      gatk --java-options \"-Xmx~{memory - overhead}G\" MarkDuplicates \\\n      ${inputBams[@]/#/--INPUT } \\\n      --OUTPUT=\"~{markDuplicatesFilePath}.bam\" \\\n      --METRICS_FILE=\"~{outputFileName}.metrics\" \\\n      --VALIDATION_STRINGENCY=SILENT \\\n      --REMOVE_DUPLICATES=~{removeDuplicates} \\\n      --OPTICAL_DUPLICATE_PIXEL_DISTANCE=~{opticalDuplicatePixelDistance} \\\n      --CREATE_INDEX=true \\\n      ~{markDuplicatesAdditionalParams}\n      outputBams+=(\"~{markDuplicatesFilePath}.bam\")\n      outputBamIndexes+=(\"~{markDuplicatesFilePath}.bai\")\n      # set inputs for next step\n      inputBams=(\"${outputBams[@]}\")\n      inputBamIndexes=(\"${outputBamIndexes[@]}\")\n    fi\n\n    # split N cigar reads\n    if [ \"~{doSplitNCigarReads}\" = true ]; then\n      outputBams=()\n      outputBamIndexes=()\n      gatk --java-options \"-Xmx~{memory - overhead}G\" SplitNCigarReads \\\n      ${inputBams[@]/#/--input=} \\\n      --output=\"~{splitNCigarReadsFilePath}.bam\" \\\n      --reference ~{reference} \\\n      ~{sep=\" \" prefix(\"--intervals \", intervals)} \\\n      ~{sep=\" \" prefixedReadFilters} \\\n      --create-output-bam-index true \\\n      --refactor-cigar-string ~{refactorCigarString} \\\n      ~{splitNCigarReadsAdditionalParams}\n      outputBams+=(\"~{splitNCigarReadsFilePath}.bam\")\n      outputBamIndexes+=(\"~{splitNCigarReadsFilePath}.bai\")\n      # set inputs for next step\n      inputBams=(\"${outputBams[@]}\")\n      inputBamIndexes=(\"${outputBamIndexes[@]}\")\n    fi\n\n    # catch all - need to merge filtered+split bams if MarkDuplicates or SplitNCigarReads isn't called\n    if [ \"~{doMarkDuplicates}\" = false ] && [ \"~{doSplitNCigarReads}\" = false ]; then\n      gatk --java-options \"-Xmx~{memory - overhead}G\" MergeSamFiles \\\n      ${inputBams[@]/#/--INPUT=} \\\n      --OUTPUT=\"~{filteredFileName}.bam\" \\\n      --CREATE_INDEX=true \\\n      --SORT_ORDER=coordinate \\\n      --ASSUME_SORTED=false \\\n      --USE_THREADING=true \\\n      --VALIDATION_STRINGENCY=SILENT\n    fi\n  >>>\n\n  output {\n    File preprocessedBam = if doSplitNCigarReads then\n                            \"~{splitNCigarReadsFilePath}.bam\"\n                           else if doMarkDuplicates then\n                            \"~{markDuplicatesFilePath}.bam\"\n                           else if doFilter then\n                            \"~{filteredFilePath}.bam\"\n                           else \"~{filteredFileName}.bam\"\n    File preprocessedBamIndex = if doSplitNCigarReads then\n                                  \"~{splitNCigarReadsFilePath}.bai\"\n                                else if doMarkDuplicates then\n                                  \"~{markDuplicatesFilePath}.bai\"\n                                else if doFilter then\n                                  \"~{filteredFilePath}.bai\"\n                                else \"~{filteredFileName}.bai\"\n    File? markDuplicateMetrics = \"~{outputFileName}.metrics\"\n  }\n\n  runtime {\n    memory: \"~{memory} GB\"\n    cpu: \"~{cores}\"\n    timeout: \"~{timeout}\"\n    modules: \"~{modules}\"\n  }\n\n  parameter_meta {\n    doFilter: \"Enable/disable Samtools filtering.\"\n    doMarkDuplicates: \"Enable/disable GATK4 MarkDuplicates.\"\n    doSplitNCigarReads: \"Enable/disable GATK4 SplitNCigarReads.\"\n    outputFileName: \"Output files will be prefixed with this.\"\n    temporaryWorkingDir: \"Where to write out intermediary bam files. Only the final preprocessed bam will be written to task working directory if this is set to local tmp.\"\n    bams: \"Array of bam files to merge together.\"\n    bamIndexes: \"Array of index files for input bams.\"\n    intervals: \"One or more genomic intervals over which to operate.\"\n    filterSuffix: \"Suffix to use for filtered bams.\"\n    filterFlags: \"Samtools filter flags to apply.\"\n    minMapQuality: \"Samtools minimum mapping quality filter to apply.\"\n    filterAdditionalParams: \"Additional parameters to pass to samtools.\"\n    markDuplicatesSuffix: \"Suffix to use for duplicate marked bams.\"\n    removeDuplicates: \"MarkDuplicates remove duplicates?\"\n    opticalDuplicatePixelDistance: \"MarkDuplicates optical distance.\"\n    markDuplicatesAdditionalParams: \"Additional parameters to pass to GATK MarkDuplicates.\"\n    splitNCigarReadsSuffix: \"Suffix to use for SplitNCigarReads bams.\"\n    reference: \"Path to reference file.\"\n    refactorCigarString: \"SplitNCigarReads refactor cigar string?\"\n    readFilters: \"SplitNCigarReads read filters\"\n    splitNCigarReadsAdditionalParams: \"Additional parameters to pass to GATK SplitNCigarReads.\"\n    runtimeAttributes: \"Override default runtime attributes using this parameter (see parameter defaultRuntimeAttributes).\"\n    defaultRuntimeAttributes: \"Default runtime attributes (memory in GB, overhead in GB, cores in cpu count, timeout in hours, modules are environment modules to load before the task executes).\"\n  }\n}\n\ntask mergeBams {\n  input {\n    Array[File] bams\n    String outputFileName\n    String suffix = \".merge\"\n    String? additionalParams\n\n    Int jobMemory = 24\n    Int overhead = 6\n    Int cores = 1\n    Int timeout = 6\n    String modules = \"gatk/4.1.6.0\"\n  }\n\n  command <<<\n    set -euo pipefail\n\n    gatk --java-options \"-Xmx~{jobMemory - overhead}G\" MergeSamFiles \\\n    ~{sep=\" \" prefix(\"--INPUT=\", bams)} \\\n    --OUTPUT=\"~{outputFileName}~{suffix}.bam\" \\\n    --CREATE_INDEX=true \\\n    --SORT_ORDER=coordinate \\\n    --ASSUME_SORTED=false \\\n    --USE_THREADING=true \\\n    --VALIDATION_STRINGENCY=SILENT \\\n    ~{additionalParams}\n  >>>\n\n  output {\n    File mergedBam = \"~{outputFileName}~{suffix}.bam\"\n    File mergedBamIndex = \"~{outputFileName}~{suffix}.bai\"\n  }\n\n  runtime {\n    memory: \"~{jobMemory} GB\"\n    cpu: \"~{cores}\"\n    timeout: \"~{timeout}\"\n    modules: \"~{modules}\"\n  }\n\n  parameter_meta {\n    bams: \"Array of bam files to merge together.\"\n    outputFileName: \"Output files will be prefixed with this.\"\n    additionalParams: \"Additional parameters to pass to GATK MergeSamFiles.\"\n    jobMemory: \"Memory allocated to job (in GB).\"\n    overhead: \"Java overhead memory (in GB). jobMemory - overhead == java Xmx/heap memory.\"\n    cores: \"The number of cores to allocate to the job.\"\n    timeout: \"Maximum amount of time (in hours) the task can run for.\"\n    modules: \"Environment module name and version to load (space separated) before command execution.\"\n  }\n}\n\ntask realignerTargetCreator {\n  input {\n    Array[File] bams\n    Array[File] bamIndexes\n    String reference\n    Array[String] knownIndels\n    Array[String] intervals\n    String? downsamplingType\n    String? additionalParams\n\n    Int jobMemory = 24\n    Int overhead = 6\n    Int cores = 1\n    Int timeout = 6\n\n    # use gatk3 for now: https://github.com/broadinstitute/gatk/issues/3104\n    String modules = \"gatk/3.6-0\"\n    String gatkJar = \"$GATK_ROOT/GenomeAnalysisTK.jar\"\n  }\n\n  command <<<\n    set -euo pipefail\n\n    java -Xmx~{jobMemory - overhead}G -jar ~{gatkJar} --analysis_type RealignerTargetCreator \\\n    --reference_sequence ~{reference} \\\n    ~{sep=\" \" prefix(\"--intervals \", intervals)} \\\n    ~{sep=\" \" prefix(\"--input_file \", bams)} \\\n    ~{sep=\" \" prefix(\"--known \", knownIndels)} \\\n    --out realignerTargetCreator.intervals \\\n    ~{\"--downsampling_type \" + downsamplingType} \\\n    ~{additionalParams}\n  >>>\n\n  output {\n    File targetIntervals = \"realignerTargetCreator.intervals\"\n  }\n\n  runtime {\n    memory: \"~{jobMemory} GB\"\n    cpu: \"~{cores}\"\n    timeout: \"~{timeout}\"\n    modules: \"~{modules}\"\n  }\n\n  parameter_meta {\n    bams: \"Array of bam files to produce RTC intervals for.\"\n    bamIndexes: \"Array of index files for input bams.\"\n    reference: \"Path to reference file.\"\n    knownIndels: \"Array of input VCF files with known indels.\"\n    intervals: \"One or more genomic intervals over which to operate.\"\n    downsamplingType: \"Type of read downsampling to employ at a given locus (NONE|ALL_READS|BY_SAMPLE).\"\n    additionalParams: \"Additional parameters to pass to GATK RealignerTargetCreator.\"\n    jobMemory:  \"Memory allocated to job (in GB).\"\n    overhead: \"Java overhead memory (in GB). jobMemory - overhead == java Xmx/heap memory.\"\n    cores: \"The number of cores to allocate to the job.\"\n    timeout: \"Maximum amount of time (in hours) the task can run for.\"\n    modules: \"Environment module name and version to load (space separated) before command execution.\"\n    gatkJar: \"Path to GATK jar.\"\n  }\n}\n\ntask indelRealign {\n  input {\n    Array[File] bams\n    Array[File] bamIndexes\n    Array[String] intervals\n    String reference\n    Array[String] knownAlleles\n    File targetIntervals\n    String? additionalParams\n\n    Int jobMemory = 24\n    Int overhead = 6\n    Int cores = 1\n    Int timeout = 6\n\n    # use gatk3 for now: https://github.com/broadinstitute/gatk/issues/3104\n    String modules = \"python/3.7 gatk/3.6-0\"\n    String gatkJar = \"$GATK_ROOT/GenomeAnalysisTK.jar\"\n  }\n\n  command <<<\n    set -euo pipefail\n\n    # generate gatk nWayOut file\n    python3 <<CODE\n    import os\n    import csv\n\n    with open('~{write_lines(bams)}') as f:\n        bamFiles = f.read().splitlines()\n\n    nWayOut = []\n    for bam in bamFiles:\n        fileName = os.path.basename(bam)\n        realignedFileName = os.path.splitext(fileName)[0] + \".realigned.bam\"\n        nWayOut.append([fileName, realignedFileName])\n\n    with open('input_output.map', 'w') as f:\n        tsv_writer = csv.writer(f, delimiter='\\t')\n        tsv_writer.writerows(nWayOut)\n    CODE\n\n    java -Xmx~{jobMemory - overhead}G -jar ~{gatkJar} --analysis_type IndelRealigner \\\n    --reference_sequence ~{reference} \\\n    ~{sep=\" \" prefix(\"--intervals \", intervals)} \\\n    ~{sep=\" \" prefix(\"--input_file \", bams)} \\\n    --targetIntervals ~{targetIntervals} \\\n    ~{sep=\" \" prefix(\"--knownAlleles \", knownAlleles)} \\\n    --bam_compression 0 \\\n    --nWayOut input_output.map \\\n    ~{additionalParams}\n  >>>\n\n  output {\n    Array[File] indelRealignedBams = glob(\"*.bam\")\n    Array[File] indelRealignedBamIndexes = glob(\"*.bai\")\n  }\n\n  runtime {\n    memory: \"~{jobMemory} GB\"\n    cpu: \"~{cores}\"\n    timeout: \"~{timeout}\"\n    modules: \"~{modules}\"\n  }\n\n  parameter_meta {\n    bams: \"Array of bam files to indel realign together.\"\n    bamIndexes: \"Array of index files for input bams.\"\n    intervals: \"One or more genomic intervals over which to operate.\"\n    reference: \"Path to reference file.\"\n    knownAlleles: \"Array of input VCF files with known indels.\"\n    targetIntervals: \"Intervals file output from RealignerTargetCreator.\"\n    additionalParams: \"Additional parameters to pass to GATK IndelRealigner.\"\n    jobMemory:  \"Memory allocated to job (in GB).\"\n    overhead: \"Java overhead memory (in GB). jobMemory - overhead == java Xmx/heap memory.\"\n    cores: \"The number of cores to allocate to the job.\"\n    timeout: \"Maximum amount of time (in hours) the task can run for.\"\n    modules: \"Environment module name and version to load (space separated) before command execution.\"\n    gatkJar: \"Path to GATK jar.\"\n  }\n}\n\ntask baseQualityScoreRecalibration {\n  input {\n    Array[File] bams\n    String reference\n    Array[String] intervals = []\n    Array[String] knownSites\n    String? additionalParams\n    String outputFileName = \"gatk.recalibration.csv\"\n\n    Int jobMemory = 24\n    Int overhead = 6\n    Int cores = 1\n    Int timeout = 6\n    String modules = \"gatk/4.1.6.0\"\n  }\n\n  # workaround for this issue https://github.com/broadinstitute/cromwell/issues/5092\n  # ~{sep=\" \" prefix(\"--intervals \", intervals)}\n  Array[String] prefixedIntervals = prefix(\"--intervals \", intervals)\n\n  command <<<\n    set -euo pipefail\n\n    gatk --java-options \"-Xmx~{jobMemory - overhead}G\" BaseRecalibrator \\\n    --reference ~{reference} \\\n    ~{sep=\" \" prefixedIntervals} \\\n    ~{sep=\" \" prefix(\"--input=\", bams)} \\\n    ~{sep=\" \" prefix(\"--known-sites \", knownSites)} \\\n    --output=~{outputFileName} \\\n    ~{additionalParams}\n  >>>\n\n  output {\n    File recalibrationTable = outputFileName\n  }\n\n  runtime {\n    memory: \"~{jobMemory} GB\"\n    cpu: \"~{cores}\"\n    timeout: \"~{timeout}\"\n    modules: \"~{modules}\"\n  }\n\n  parameter_meta {\n    bams: \"Array of bam files to produce a recalibration table for.\"\n    reference: \"Path to reference file.\"\n    intervals: \"One or more genomic intervals over which to operate.\"\n    knownSites: \"Array of VCF with known polymorphic sites used to exclude regions around known polymorphisms from analysis.\"\n    additionalParams: \"Additional parameters to pass to GATK BaseRecalibrator.\"\n    outputFileName: \"Recalibration table file name.\"\n    jobMemory:  \"Memory allocated to job (in GB).\"\n    overhead: \"Java overhead memory (in GB). jobMemory - overhead == java Xmx/heap memory.\"\n    cores: \"The number of cores to allocate to the job.\"\n    timeout: \"Maximum amount of time (in hours) the task can run for.\"\n    modules: \"Environment module name and version to load (space separated) before command execution.\"\n  }\n}\n\ntask gatherBQSRReports {\n  input {\n    Array[File] recalibrationTables\n    String? additionalParams\n    String outputFileName = \"gatk.recalibration.csv\"\n\n    Int jobMemory = 24\n    Int overhead = 6\n    Int cores = 1\n    Int timeout = 6\n    String modules = \"gatk/4.1.6.0\"\n  }\n\n  command <<<\n    set -euo pipefail\n\n    gatk --java-options \"-Xmx~{jobMemory - overhead}G\" GatherBQSRReports \\\n    ~{sep=\" \" prefix(\"--input=\", recalibrationTables)} \\\n    --output ~{outputFileName} \\\n    ~{additionalParams}\n  >>>\n\n  output {\n    File recalibrationTable = outputFileName\n  }\n\n  runtime {\n    memory: \"~{jobMemory} GB\"\n    cpu: \"~{cores}\"\n    timeout: \"~{timeout}\"\n    modules: \"~{modules}\"\n  }\n\n  parameter_meta {\n    recalibrationTables: \"Array of recalibration tables to merge.\"\n    additionalParams: \"Additional parameters to pass to GATK GatherBQSRReports.\"\n    outputFileName: \"Recalibration table file name.\"\n    jobMemory:  \"Memory allocated to job (in GB).\"\n    overhead: \"Java overhead memory (in GB). jobMemory - overhead == java Xmx/heap memory.\"\n    cores: \"The number of cores to allocate to the job.\"\n    timeout: \"Maximum amount of time (in hours) the task can run for.\"\n    modules: \"Environment module name and version to load (space separated) before command execution.\"\n  }\n}\n\ntask analyzeCovariates {\n  input {\n    File recalibrationTable\n    String? additionalParams\n    String outputFileName = \"gatk.recalibration.pdf\"\n\n    Int jobMemory = 24\n    Int overhead = 6\n    Int cores = 1\n    Int timeout = 6\n    String modules = \"gatk/4.1.6.0\"\n  }\n\n  command <<<\n    set -euo pipefail\n\n    gatk --java-options \"-Xmx~{jobMemory - overhead}G\" AnalyzeCovariates \\\n    --bqsr-recal-file=~{recalibrationTable} \\\n    --plots-report-file ~{outputFileName} \\\n    ~{additionalParams}\n  >>>\n\n  output {\n    File recalibrationReport = outputFileName\n  }\n\n  runtime {\n    memory: \"~{jobMemory} GB\"\n    cpu: \"~{cores}\"\n    timeout: \"~{timeout}\"\n    modules: \"~{modules}\"\n  }\n\n  parameter_meta {\n    recalibrationTable: \"Recalibration table to produce report for.\"\n    additionalParams: \"Additional parameters to pass to GATK AnalyzeCovariates\"\n    outputFileName: \"Recalibration report file name.\"\n    jobMemory:  \"Memory allocated to job (in GB).\"\n    overhead: \"Java overhead memory (in GB). jobMemory - overhead == java Xmx/heap memory.\"\n    cores: \"The number of cores to allocate to the job.\"\n    timeout: \"Maximum amount of time (in hours) the task can run for.\"\n    modules: \"Environment module name and version to load (space separated) before command execution.\"\n  }\n}\n\ntask applyBaseQualityScoreRecalibration {\n  input {\n    File recalibrationTable\n    File bam\n    String outputFileName = basename(bam, \".bam\")\n    String suffix = \".recalibrated\"\n    String? additionalParams\n\n    Int jobMemory = 24\n    Int overhead = 6\n    Int cores = 1\n    Int timeout = 6\n    String modules = \"gatk/4.1.6.0\"\n  }\n\n  command <<<\n    set -euo pipefail\n\n    gatk --java-options \"-Xmx~{jobMemory - overhead}G\" ApplyBQSR \\\n    --bqsr-recal-file=~{recalibrationTable} \\\n    ~{sep=\" \" prefix(\"--input=\", [bam])} \\\n    --output ~{outputFileName}~{suffix}.bam \\\n    ~{additionalParams}\n  >>>\n\n  output {\n    File recalibratedBam = outputFileName + suffix + \".bam\"\n    File recalibratedBamIndex = outputFileName + suffix + \".bai\"\n  }\n\n  runtime {\n    memory: \"~{jobMemory} GB\"\n    cpu: \"~{cores}\"\n    timeout: \"~{timeout}\"\n    modules: \"~{modules}\"\n  }\n\n  parameter_meta {\n    recalibrationTable: \"Recalibration table to apply to all input bams.\"\n    bam: \"Bam file to recalibrate.\"\n    outputFileName: \"Output files will be prefixed with this.\"\n    suffix: \"Suffix to use for recalibrated bams.\"\n    additionalParams: \"Additional parameters to pass to GATK ApplyBQSR.\"\n    jobMemory:  \"Memory allocated to job (in GB).\"\n    overhead: \"Java overhead memory (in GB). jobMemory - overhead == java Xmx/heap memory.\"\n    cores: \"The number of cores to allocate to the job.\"\n    timeout: \"Maximum amount of time (in hours) the task can run for.\"\n    modules: \"Environment module name and version to load (space separated) before command execution.\"\n  }\n}\n\ntask collectFilesBySample {\n  input {\n    Array[InputGroup] inputGroups\n    Array[File] bams\n    Array[File] bamIndexes\n\n    Int jobMemory = 1\n    Int cores = 1\n    Int timeout = 1\n    String modules = \"python/3.7\"\n  }\n\n  InputGroups wrappedInputGroups = {\"inputGroups\": inputGroups}\n\n  command <<<\n    set -euo pipefail\n\n    python3 <<CODE\n    import json\n    import os\n    import re\n\n    with open('~{write_json(wrappedInputGroups)}') as f:\n        inputGroups = json.load(f)\n    with open('~{write_lines(bams)}') as f:\n        bamFiles = f.read().splitlines()\n    with open('~{write_lines(bamIndexes)}') as f:\n        bamIndexFiles = f.read().splitlines()\n\n    filesByOutputIdentifier = []\n    for outputIdentifier in [inputGroup['outputIdentifier'] for inputGroup in inputGroups['inputGroups']]:\n        # select bams and bamIndexes for outputIdentifier (preprocessBam prefixes the outputIdentifier, so include that too)\n        bams = [bam for bam in bamFiles if re.match(\"^\" + outputIdentifier + \"\\.\", os.path.basename(bam))]\n        bais = [bai for bai in bamIndexFiles if re.match(\"^\" + outputIdentifier + \"\\.\", os.path.basename(bai))]\n\n        fileNames = list(set([os.path.splitext(os.path.basename(f))[0] for f in bams + bais]))\n        if len(fileNames) != 1:\n            raise Exception(\"Unable to determine unique fileName from fileNames = [\" + ','.join(f for f in fileNames) + \"]\")\n        else:\n            fileName = fileNames[0]\n\n        filesByOutputIdentifier.append({\n            'outputIdentifier': outputIdentifier,\n            'outputFileName': fileName,\n            'bams': bams,\n            'bamIndexes': bais})\n\n    # wrap the array into collectionGroups object\n    wrappedFilesByOutputIdentifier = {'collectionGroups': filesByOutputIdentifier}\n\n    with open('filesByOutputIdentifier.json', 'w') as f:\n        json.dump(wrappedFilesByOutputIdentifier, f, indent=4)\n    CODE\n  >>>\n\n  output {\n    CollectionGroups filesByOutputIdentifier = read_json(\"filesByOutputIdentifier.json\")\n  }\n\n  runtime {\n    memory: \"~{jobMemory} GB\"\n    cpu: \"~{cores}\"\n    timeout: \"~{timeout}\"\n    modules: \"~{modules}\"\n  }\n\n  parameter_meta {\n    inputGroups: \"Array of objects describing output file groups. The output file group name is used to partition input bams by name.\"\n    bams: \"Array of bams to partition by inputGroup output file name.\"\n    bamIndexes: \"Array of index files for input bams.\"\n    jobMemory:  \"Memory allocated to job (in GB).\"\n    cores: \"The number of cores to allocate to the job.\"\n    timeout: \"Maximum amount of time (in hours) the task can run for.\"\n    modules: \"Environment module name and version to load (space separated) before command execution.\"\n  }\n}\n\nstruct BamAndBamIndex {\n  File bam\n  File bamIndex\n}\n\nstruct InputGroup {\n  String outputIdentifier\n  Array[BamAndBamIndex]+ bamAndBamIndexInputs\n}\n\nstruct InputGroups {\n  Array[InputGroup] inputGroups\n}\n\nstruct CollectionGroup {\n  String outputIdentifier\n  String outputFileName\n  Array[File] bams\n  Array[File] bamIndexes\n}\n\nstruct CollectionGroups {\n  Array[CollectionGroup] collectionGroups\n}\n\nstruct OutputGroup {\n  String outputIdentifier\n  File bam\n  File bamIndex\n}\n\nstruct RuntimeAttributes {\n  Int? memory\n  Int? overhead\n  Int? cores\n  Int? timeout\n  String? modules\n  String? id # optional internal id\n}\n\nstruct DefaultRuntimeAttributes {\n  Int memory\n  Int overhead\n  Int cores\n  Int timeout\n  String modules\n}\n\nstruct Intervals {\n  String id\n  Array[String] intervalsList\n}\n\nstruct IntervalsList {\n  Array[Intervals] intervalsList\n}\n"
}